---
permalink: /series/HosseinAbedi/optimization/optimization-intro-1
title: بهینه‌سازی
author: Hossein Abedi
excerpt: معرفی بهینه‌سازی به همراه بررسی تعدادی از روش‌های متداول بهینه‌سازی به همراه مثال
is_cover: false
---

##  سردکردن تدریجی فلزات

سردکردن تدریجی فلزات 
(Simulated Annealing)
یه الگوریتم معروف توی بهینه‌سازیه که
ایدش خیلی نسبتا سادس ولی کاربردای زیادی توی حل مساله‌های مختلف داره.
  
## ایده‌‌ی کلی روش
در این روش مثل خیلی از روش‌های دیگه‌ی بهینه‌سازی فرض بر اینه که ما می‌خواهیم فضای جستجوی مساله‌ رو طوری بگردیم که به یه نقطه‌ی بهینه‌ی سراسری (global optimum) برسیم. طبق معمول مشکل ما اینه که الگوریتم‌ها هیچ دانشی ممکنه از فضای جستجو نداشنه باشن و فقط در هر قدم می‌تونن چند تا ارزیابی تابع انجام بدن یعنی فقط می‌تونن تا حدی حدث بزنن که 
**عرصه‌ی شایستگی** (fitness landscape) 
 اطرافشون چه شکلیه.
در واقع بفهمن که از نظر بهینگی منطقه‌ای که الان توش هستن چقدر از نواحی قبلی بهتر بوده.

در صورتی هم که تابع مورد نظر چند قله‌ای باشه (که معمولا هم هست) کلا فرار از نقاط بهینه‌ی محلی (local optimum) مشکل بزرگ روش‌های مورد استفادس که هر کدوم یک یا چند تا مکانیزم برای فرار از اون‌ها و رسیدن به نقاط بهینه‌ی سراسری رو استفاده می‌کنن.

![شایستگی](/assets/images/HosseinAbedi/images/opt_0.png)


این روش
 با یه **نامزد جواب** 
  به صورت تصادی شروع می‌کنه و به صورت یکنواخت فضا رو می گرده. در اول کار جواب‌هایی رو که از جواب فعلی بدتر‌ هستن رو با یه احتمالی می‌پذیره ولی به مرور زمان این احتمال که جواب‌های بدتر رو بپذیره با یه مکانیزمی کمتر می‌شه. در واقع در اول کار **جستجوی عمومی** (الگوریتم بخش زیادی از فضا رو می‌گرده)
زیادی داریم و در آخرای کار برعکس میزان جستجوی **جستجوی محلی** (جستجو بیشتر اطراف بهترین جاییه که تا حالا پیدا کردیم) خیلی زیاد می‌شه. 
  
  ويژگی‌های این روش به‌ شرح هستن:
* استفاده در بهینه‌سازی پیوسته و گسسته: خیلی از روش‌های معروفی که وجود دارن برای بهینه‌سازی پیوسته تعریف شدن و زمانی که فضای جستجو گسسته‌ هستش قابل استفاده نیستن. مثلا برای کارایی مثل حل مساله‌ی سودوکو و یا انتخاب ویژگی در مسائل یادگیری ماشین می‌شه از
SA
استفاده کرد.
* این روش یه روش  احتمالاتی 
(stochastic)
حساب می‌شه که در هر تکرار با مقدار شروع مختلف ممکنه جواب‌هایی متفاوت به ما بده. ولی در کل مزایای خیلی از روش‌های احتمالاتی دیگرم مثل عدم احتیاج به مشتق تابع هدف و زمان نسبتا کوتاه اجرا رو داراست.
* این متد یه روش تک‌جوابی به حساب میاد و وقتی هزینه‌ی ارزیابی‌های تابع خیلی ممکنه بالا باشه ممکنه خیلی به کار بیاد. در عین حال خیلی هم سادس و فهمیدن مکانیزم اجرای نسخه‌های مختلف این الگوریتم چندان زیاد نیست.

## پیاده‌سازی 

مثال زیر رو که مربوط به تابع
[Hölder table function](https://en.wikipedia.org/wiki/Test_functions_for_optimization)
هستش رو در نظر بگیرین. این تابع یه تابع دوبعدی هستش که به عنوان یه تابع محک برای بررسی عملکرد روش‌های بهینه‌سازی مورد استفاده قرار می‌گیره.
این تابع توی دامنه‌ی جستجوی خودش چندتا نقطه‌ی بهینه‌ی سراسری و تعداد زیادی نقطه‌ی بهینه‌ی محلی داره.
```python 
import numpy as np

def f(s: 'candidate solution') -> 'f(x)':
    """Hölder table function, for more information please have a look at 
       `https://en.wikipedia.org/wiki/Test_functions_for_optimization`
    """
    x = s[0]
    y = s[1]
    return -np.abs(np.sin(x) *np.cos(y) * np.exp(np.abs(1 - np.sqrt(np.power(x, 2) + np.power(y, 2)) / np.pi)))
```
با یه پیاده‌سازی خیلی ساده از
SA
سعی می‌کنیم مقدار بهینه‌ی این تابع رو پید کنیم.


از نظر مفهومی می‌توان یک مساله‌ی بهینه‌سازی را به‌صورت کمینه‌ و یا بیشنه کردن یک تابع مانند 
$$f$$،
در زیر مجموعه‌ای از دامنه‌اش در نظر گرفت. این دو مساله به سادگی با تغییر علامت مقادیر خروجی تابع مورد نظر، قابل تبدیل به هم هستند.
از نظر ریاضی می‌توان مسائل بهینه‌سازی  برای کمینه‌سازی یک تابع  را به شکل‌ رسمی زیر نوشت:

\begin{align}
minimize ~f_i(x),~x\in \Re^n and~ i=1, 2,...,I
\end{align}

با داشتن شرایط زیر

\begin{align}
&h_j(x)=0,~(j=1, 2,...,J),\\
&g_k(x) \leq0,~(k=1, 2,...,K).
\end{align}


که توابع $$f$$، $$h$$ و $$g$$ معرف سه تابع هستند که  بردار ورودی  ‌آن‌ها $$x$$ می‌باشد و دو تابع آخر قیود اعمال‌شده روی $$f$$  می‌باشند. تابع $$f_i(x)$$ را در مسائل بهینه‌سازی، تابع هدف می‌نامند. در صورتی که 
$$i=1$$
باشد، مساله بهینه‌سازی تک‌هدفه و در غیر این صورت چند‌هدفه نام دارد. فصای جستجو مساله 
$$\Re^n$$
می‌باشد که درون آن به‌دنبال جواب هستیم و فضای حاصل از مقادیر خروجی توابع هدف را فضای جواب می‌نامیم. عبارات  
$$g_k$$
و 
$$h_j$$
قیود مساله بهینه‌سازی هستند که می‌خواهیم توابع هدف را تحت این قیود کمینه کنیم.
در تعدادی از مسائل،  تابع هدفی وجود ندارد و فقط با قیود روبرو هستیم در این‌گونه مسائل، هر ترکیبی از قیود می‌تواند جواب مورد نظر باشد.


##  توجه

دسته‌بندی روش‌های محاسباتی به دلیل تنوع این روش‌ها و ماهیت مساله‌هایی که می‌توان هر روش‌ را در آن اعمال نمود بسیار متنوع است. برای همین در ادامه با آوردن مثال‌هایی  از مساله‌های مختلف بهینه‌سازی به بررسی ويژگی‌های این روش‌ها و شرایط کاربرد آن‌ها خواهیم پرداخت.  


